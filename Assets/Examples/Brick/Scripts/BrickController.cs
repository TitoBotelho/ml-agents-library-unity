using System;
using UnityEngine;
using UnityEngine.SceneManagement;
using Unity.MLAgents;
using UnityEngine.Serialization;

/// <summary>
/// An example of how to use ML-Agents without inheriting from the Agent class.
/// Observations are generated by the attached SensorComponent, and the actions
/// are retrieved from the Agent.
/// </summary>
public class BrickController : MonoBehaviour
{
    public float timeBetweenDecisionsAtInference;
    float m_TimeSinceDecision;
    // Campo renomeado definitivamente (removidos FormerlySerializedAs)
    [HideInInspector] public int positionX; // X
    [HideInInspector] public int positionZ; // Z

    [Header("Goal Positions (fixos)")]
    [SerializeField] int smallX = 0;
    [SerializeField] int smallZ = 0;
    [SerializeField] int largeX = 7;
    [SerializeField] int largeZ = 7;

    public GameObject largeGoal;
    public GameObject smallGoal;
    const int k_MinPosition = 0;
    const int k_MaxPosition = 7; // Se quiser alcançar LargeGoal=14 aumente este valor ou reduza k_LargeGoalPosition
    public const int k_Extents = k_MaxPosition - k_MinPosition;

    Agent m_Agent;

    public void Awake() { }

    public void OnEnable()
    {
        m_Agent = GetComponent<Agent>();
        positionX = 3;
        positionZ = 3;
        transform.position = new Vector3(positionX, 0f, positionZ);
        // Garantir metas dentro do limite
        smallX = Mathf.Clamp(smallX, k_MinPosition, k_MaxPosition);
        smallZ = Mathf.Clamp(smallZ, k_MinPosition, k_MaxPosition);
        largeX = Mathf.Clamp(largeX, k_MinPosition, k_MaxPosition);
        largeZ = Mathf.Clamp(largeZ, k_MinPosition, k_MaxPosition);
        smallGoal.transform.position = new Vector3(smallX, 0f, smallZ);
        largeGoal.transform.position = new Vector3(largeX, 0f, largeZ);
    }

    /// <summary>
    /// Mantém compatibilidade: movimento apenas no eixo X.
    /// </summary>
    public void MoveDirection(int direction)
    {
        Move2D(direction, 0);
    }

    /// <summary>
    /// Novo movimento 2D (dx, dz) com limites e mesmas recompensas.
    /// </summary>
    public void Move2D(int dx, int dz)
    {
        positionX += dx;
        positionZ += dz;
        if (positionX < k_MinPosition) positionX = k_MinPosition;
        if (positionX > k_MaxPosition) positionX = k_MaxPosition;
        if (positionZ < k_MinPosition) positionZ = k_MinPosition;
        if (positionZ > k_MaxPosition) positionZ = k_MaxPosition;
        transform.position = new Vector3(positionX, 0f, positionZ);
        m_Agent.AddReward(-0.01f);
        CheckGoals();
    }

    void CheckGoals()
    {
        bool onSmall = positionX == smallX && positionZ == smallZ;
        bool onLarge = positionX == largeX && positionZ == largeZ;
        if (onSmall)
        {
            m_Agent.AddReward(0.1f);
            m_Agent.EndEpisode();
            ResetAgent();
        }
        else if (onLarge)
        {
            m_Agent.AddReward(1f);
            m_Agent.EndEpisode();
            ResetAgent();
        }
    }

    public void ResetAgent()
    {
        SceneManager.LoadScene(SceneManager.GetActiveScene().name);
        m_Agent = null;
    }

    public void FixedUpdate()
    {
        WaitTimeInference();
    }

    void WaitTimeInference()
    {
        if (m_Agent == null)
        {
            return;
        }
        if (Academy.Instance.IsCommunicatorOn)
        {
            m_Agent?.RequestDecision();
        }
        else
        {
            if (m_TimeSinceDecision >= timeBetweenDecisionsAtInference)
            {
                m_TimeSinceDecision = 0f;
                m_Agent?.RequestDecision();
            }
            else
            {
                m_TimeSinceDecision += Time.fixedDeltaTime;
            }
        }
    }
}
